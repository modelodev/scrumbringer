# Story 2.6: Métricas v1 (event log + Mi panel + Admin overview)

## Status: Ready

## Story
**As an** org admin (and as a member),
**I want** lightweight MVP metrics based on an event log,
**so that** I can monitor pool health and my own activity without introducing leaderboards.

## Acceptance Criteria
1. **Event log persisted**: The server records a minimal event log for task lifecycle actions (at least: task created, claimed, released, completed).
2. **No leaderboard**: Metrics endpoints and UI do not expose user rankings or “top users” lists.
3. **My metrics endpoint**: `GET /api/v1/me/metrics` exists and is authenticated (OA/PA/M).
   - Query: `window_days` (optional, integer). Default: `30` when omitted.
   - Response: `200` `{ data: { metrics: MyMetrics } }`.
4. **Admin overview endpoint**: `GET /api/v1/org/metrics/overview` exists and is org-admin only.
   - Query: `window_days` (optional, integer). Default: `30` when omitted.
   - Response: `200` `{ data: { overview: MetricsOverview } }`.
5. **KPI alignment**: Admin overview includes the MVP KPIs from the brief (computed org-wide and/or by project where applicable):
   - `time_to_first_claim` (from first successful login to first successful claim; null if no claim in window)
   - `pool_flow_ratio` (defined as `completed / claimed` in the requested window; if `claimed=0`, ratio is `null`)
   - `release_rate` (defined as `released / claimed` in the requested window; if `claimed=0`, rate is `null`)
6. **Distributions**: Admin overview includes distributions (histograms/buckets) for at least `time_to_first_claim` and `release_rate`.
7. **Drill-down limited to project/tasks**: Admin can drill down only to project and task level.
   - `GET /api/v1/org/metrics/projects/:project_id/tasks` returns a task list with fields needed to inspect the KPI drivers.
   - Query: `window_days` (optional, integer). Default: `30` when omitted.
8. **UI surfaces exist**:
   - Member UI has a “My Metrics” panel consuming `GET /api/v1/me/metrics`.
   - Admin UI has an “Metrics Overview” panel consuming `GET /api/v1/org/metrics/overview`.
9. **Consistent API conventions**: Responses use the `{ data: ... }` envelope and error shapes from `docs/architecture/api-contract.md`.

## Tasks / Subtasks
- [ ] Define event log model and persistence (AC: 1)
  - [ ] Add a DB table for events (e.g. `events` or `task_events`) with: `id`, `org_id`, `project_id`, `task_id`, `actor_user_id`, `event_type`, `created_at` (AC: 1)
  - [ ] Decide minimal `event_type` vocabulary (create/claim/release/complete) (AC: 1)
- [ ] Emit events from existing task endpoints (AC: 1)
  - [ ] On task create: emit `task_created` (AC: 1)
  - [ ] On claim/release/complete: emit corresponding events (AC: 1)
- [ ] Implement metrics queries and endpoints (AC: 3, 4, 5, 6, 7, 9)
   - [ ] Implement `GET /api/v1/me/metrics` (AC: 3)
     - [ ] Support `window_days` query param; default to `30` days when omitted (AC: 3)
     - [ ] Provide counts for the current user (claimed, released, completed) within the requested window (AC: 3)
   - [ ] Implement `GET /api/v1/org/metrics/overview` (AC: 4, 5, 6)
     - [ ] Support `window_days` query param; default to `30` days when omitted (AC: 4)
     - [ ] Compute `time_to_first_claim` buckets (e.g. 0–1h, 1–4h, 4–24h, >24h) (AC: 6)
    - [ ] Compute `release_rate` as `releases / claims` (org-wide and by project) (AC: 5, 6)
    - [ ] Compute `pool_flow_ratio` (document chosen definition clearly in the response fields) (AC: 5)
   - [ ] Implement `GET /api/v1/org/metrics/projects/:project_id/tasks` (AC: 7)
     - [ ] Support `window_days` query param; default to `30` days when omitted (AC: 7)
     - [ ] Return tasks in the project with derived fields needed for drill-down (created_at, first_claimed_at?, release_count?, status, etc.) (AC: 7)
- [ ] Implement UI panels (AC: 8)
  - [ ] Member: add a “My Metrics” section/panel and render the returned metrics (AC: 8)
  - [ ] Admin: add a “Metrics Overview” section/panel and render distributions + KPI summaries (AC: 8)
  - [ ] Drill-down: from Admin overview, navigate to a project-level task list view (AC: 7)
- [ ] Add tests (AC: 1, 3, 4, 7)
  - [ ] Server: event emission on claim/release/complete (AC: 1)
  - [ ] Server: authz for org admin overview (403 for non-org-admin) (AC: 4)
  - [ ] Server: drill-down endpoint is project-scoped and returns expected shape (AC: 7)
  - [ ] Client: decode + render for my metrics and admin overview (AC: 8)

## Dev Notes
### Source of truth
- KPI definitions and targets are stated in the brief: `docs/brief.md` (see “Métricas MVP”).
- API conventions (envelope, error shape, roles) are defined in: `docs/architecture/api-contract.md`.

### Suggested endpoints (new)
- `GET /api/v1/me/metrics`
- `GET /api/v1/org/metrics/overview`
- `GET /api/v1/org/metrics/projects/:project_id/tasks`

### KPI notes (MVP)
- The brief defines targets for:
  - `time_to_first_claim` (< 4h P50)
  - `pool_flow_ratio` (> 0.8)
  - `release_rate` (< 15%)
  [Source: `docs/brief.md` “Métricas MVP”]
- This story should compute and expose these metrics; it should not introduce competitive ranking/leaderboards.

## Testing
- Server: `make test`
- Client: `apps/client: gleam test`

## Change Log
| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2026-01-14 | 1.0 | Initial draft | po |
| 2026-01-14 | 1.1 | Ready for dev (DoR passed; KPI formulas fixed; window_days default 30) | po |

## Dev Agent Record

## QA Results
